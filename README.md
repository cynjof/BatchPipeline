# Batch Pipeline Project

## Overview



### Data Visualization


### Data Architecture
This data engineering project includes the following:
- Airflow: To schedule and orchestrate DAGs.
- Postgres: This database stores Airflowâ€™s details and has a schema to represent upstream databases.
- DuckDB: To act as our warehouse
- Quarto with Plotly: To convert code in markdown format to HTML files that can be embedded in your app or served as is.
- Apache Spark: This is used to process our data, specifically to run a classification algorithm.
- Minio: To provide an S3 compatible open source storage system.
  
![image](https://github.com/user-attachments/assets/ca4a31fc-72af-4916-a4c5-2db9de5248c9)

![image](https://github.com/user-attachments/assets/e81e4d3b-dce3-42bf-9e72-14280b62f190)

## Prerequisites



## How to Run This Project

Step-by-step instructions to run the project.

1. Install x packages
2. Run command: `python x`
3. Make sure it's running properly by checking z
4. To clean up at the end, run script: `python cleanup.py`

## Lessons Learned

